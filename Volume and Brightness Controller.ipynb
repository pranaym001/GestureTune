{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8054a3-b3b1-488a-bbe7-600b6df81d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import screen_brightness_control as sbc\n",
    "from math import hypot, sqrt\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Audio setup for controlling system volume\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    volRange = volume.GetVolumeRange()\n",
    "    minVol, maxVol, _ = volRange\n",
    "\n",
    "    # Initialize MediaPipe Hand Detection\n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        min_detection_confidence=0.8,\n",
    "        min_tracking_confidence=0.8,\n",
    "        max_num_hands=2)\n",
    "\n",
    "    draw = mp.solutions.drawing_utils\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video capture\")\n",
    "        return\n",
    "\n",
    "    # Control variables\n",
    "    smooth_brightness = sbc.get_brightness()[0]\n",
    "    smooth_volume = volume.GetMasterVolumeLevelScalar() * 100\n",
    "    prev_volume = smooth_volume\n",
    "    \n",
    "    # Parameters for control\n",
    "    MIN_DISTANCE = 20\n",
    "    MAX_DISTANCE = 230\n",
    "    SMOOTHING_FACTOR = 0.1  # Reduced smoothing factor for quicker response\n",
    "    \n",
    "    # Smoothing queues\n",
    "    brightness_queue = deque(maxlen=5)  # Adjust queue length for desired smoothness\n",
    "    volume_queue = deque(maxlen=5)\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)  # Mirror the frame\n",
    "            frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            processed = hands.process(frameRGB)\n",
    "\n",
    "            # Initialize landmark lists\n",
    "            left_landmark_list = []\n",
    "            right_landmark_list = []\n",
    "\n",
    "            if processed.multi_hand_landmarks:\n",
    "                for i, hand_landmarks in enumerate(processed.multi_hand_landmarks):\n",
    "                    # Get handedness (left/right) - this is the key fix\n",
    "                    if processed.multi_handedness:\n",
    "                        hand_label = processed.multi_handedness[i].classification[0].label\n",
    "                    else:\n",
    "                        # Default to right hand if handedness isn't available\n",
    "                        hand_label = \"Right\" if i == 0 else \"Left\"\n",
    "                    \n",
    "                    # Get landmarks in pixel coordinates\n",
    "                    landmarks = [(landmark.x, landmark.y) for landmark in hand_landmarks.landmark]\n",
    "                    \n",
    "                    # Assign to correct list based on hand label\n",
    "                    if hand_label == \"Left\":\n",
    "                        left_landmark_list = landmarks\n",
    "                    else:\n",
    "                        right_landmark_list = landmarks\n",
    "                    \n",
    "                    # Draw landmarks\n",
    "                    draw.draw_landmarks(frame, hand_landmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Brightness control with left hand\n",
    "            if left_landmark_list:\n",
    "                left_distance = get_distance(left_landmark_list, frame)\n",
    "                if left_distance > MIN_DISTANCE:\n",
    "                    b_level = np.interp(left_distance, [MIN_DISTANCE, MAX_DISTANCE], [0, 100])\n",
    "                    brightness_queue.append(b_level)\n",
    "                    smooth_brightness = np.mean(brightness_queue) #Simple average smoothing\n",
    "                    sbc.set_brightness(int(np.clip(smooth_brightness, 0, 100)))\n",
    "                else:\n",
    "                    sbc.set_brightness(0) # Ensure minimum brightness when hand is close\n",
    "\n",
    "            # Volume control with right hand - THIS IS NOW FIXED\n",
    "            if right_landmark_list:\n",
    "                right_distance = get_distance(right_landmark_list, frame)\n",
    "                if right_distance > MIN_DISTANCE:\n",
    "                    vol_level = np.interp(right_distance, [MIN_DISTANCE, MAX_DISTANCE], [0, 1])\n",
    "                    volume_queue.append(vol_level * 100)\n",
    "                    smooth_volume = np.mean(volume_queue)\n",
    "                    volume.SetMasterVolumeLevelScalar(np.clip(smooth_volume / 100, 0, 1), None)\n",
    "                    prev_volume = smooth_volume\n",
    "                else:\n",
    "                    volume.SetMasterVolumeLevelScalar(0, None) # Mute when hand is close\n",
    "                    prev_volume = 0\n",
    "\n",
    "            # Display information\n",
    "            cv2.putText(frame, f\"Brightness: {int(smooth_brightness)}%\", (10, 30),  \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Volume: {int(prev_volume)}%\", (10, 60),  \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Show which hands are detected\n",
    "            cv2.putText(frame, f\"Left Hand: {'Yes' if left_landmark_list else 'No'}\", (10, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Right Hand: {'Yes' if right_landmark_list else 'No'}\", (10, 120),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow('GestureTune', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "def get_distance(landmark_list, frame):\n",
    "    \"\"\"Calculate distance between thumb and index finger tips\"\"\"\n",
    "    if len(landmark_list) < 9:\n",
    "        return 0\n",
    "\n",
    "    # Thumb tip (4) and index finger tip (8)\n",
    "    x1, y1 = int(landmark_list[4][0] * frame.shape[1]), int(landmark_list[4][1] * frame.shape[0])\n",
    "    x2, y2 = int(landmark_list[8][0] * frame.shape[1]), int(landmark_list[8][1] * frame.shape[0])\n",
    "\n",
    "    # Draw visual feedback\n",
    "    cv2.circle(frame, (x1, y1), 7, (0, 255, 0), cv2.FILLED)\n",
    "    cv2.circle(frame, (x2, y2), 7, (0, 255, 0), cv2.FILLED)\n",
    "    cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "    cv2.putText(frame, \"Left=Brightness | Right=Volume\", (10, frame.shape[0]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150,150,255), 1)\n",
    "\n",
    "    return hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f16dd9-069d-4bce-86d3-2805ea588c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
